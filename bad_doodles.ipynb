{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bad-doodles.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODBZ9KH4j5AeadAitbbNGZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anosharahim/cs156-final-project/blob/main/bad_doodles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/My Drive/amld_data'\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "hAWEvzUZWefj",
        "outputId": "96d49e93-2497-4a9d-8336-a735754557b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b5f0a0d753a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/gdrive/My Drive/amld_data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU svgwrite\n",
        "!pip install -q magenta\n",
        "\n",
        "# import the required libraries\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import pickle as cPickle\n",
        "import codecs\n",
        "import collections\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import svgwrite\n",
        "import tensorflow as tf\n",
        "from six.moves import xrange\n",
        "\n",
        "# libraries required for visualisation:\n",
        "from IPython.display import SVG, display\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set numpy output to something sensible\n",
        "np.set_printoptions(precision=8, edgeitems=6, linewidth=200, suppress=True)\n",
        "\n",
        "# import our command line tools\n",
        "from magenta.models.sketch_rnn.sketch_rnn_train import *\n",
        "from magenta.models.sketch_rnn.model import *\n",
        "from magenta.models.sketch_rnn.utils import *\n",
        "from magenta.models.sketch_rnn.rnn import *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClNB-wMFCJ-N",
        "outputId": "aed198fe-3aab-4f2f-fb34-f39a73f1f590"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 66 kB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 30.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 210 kB 69.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 39.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 24.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 254 kB 53.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 36.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 204 kB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 49.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 366 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 191 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 981 kB 30.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 37.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 367 kB 48.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 251 kB 42.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 191 kB 55.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 59.2 MB/s \n",
            "\u001b[?25h  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pygtrie (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
            "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
            "  from numba.decorators import jit as optional_jit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# little function that displays vector images and saves them to .svg\n",
        "def draw_strokes(data, factor=0.2, svg_filename = '/tmp/sketch_rnn/svg/sample.svg'):\n",
        "  tf.gfile.MakeDirs(os.path.dirname(svg_filename))\n",
        "  min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "  dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "  dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "  dwg.add(dwg.rect(insert=(0, 0), size=dims,fill='white'))\n",
        "  lift_pen = 1\n",
        "  abs_x = 25 - min_x \n",
        "  abs_y = 25 - min_y\n",
        "  p = \"M%s,%s \" % (abs_x, abs_y)\n",
        "  command = \"m\"\n",
        "  for i in xrange(len(data)):\n",
        "    if (lift_pen == 1):\n",
        "      command = \"m\"\n",
        "    elif (command != \"l\"):\n",
        "      command = \"l\"\n",
        "    else:\n",
        "      command = \"\"\n",
        "    x = float(data[i,0])/factor\n",
        "    y = float(data[i,1])/factor\n",
        "    lift_pen = data[i, 2]\n",
        "    p += command+str(x)+\",\"+str(y)+\" \"\n",
        "  the_color = \"black\"\n",
        "  stroke_width = 1\n",
        "  dwg.add(dwg.path(p).stroke(the_color,stroke_width).fill(\"none\"))\n",
        "  dwg.save()\n",
        "  display(SVG(dwg.tostring()))\n",
        "\n",
        "# generate a 2D grid of many vector drawings\n",
        "def make_grid_svg(s_list, grid_space=10.0, grid_space_x=16.0):\n",
        "  def get_start_and_end(x):\n",
        "    x = np.array(x)\n",
        "    x = x[:, 0:2]\n",
        "    x_start = x[0]\n",
        "    x_end = x.sum(axis=0)\n",
        "    x = x.cumsum(axis=0)\n",
        "    x_max = x.max(axis=0)\n",
        "    x_min = x.min(axis=0)\n",
        "    center_loc = (x_max+x_min)*0.5\n",
        "    return x_start-center_loc, x_end\n",
        "  x_pos = 0.0\n",
        "  y_pos = 0.0\n",
        "  result = [[x_pos, y_pos, 1]]\n",
        "  for sample in s_list:\n",
        "    s = sample[0]\n",
        "    grid_loc = sample[1]\n",
        "    grid_y = grid_loc[0]*grid_space+grid_space*0.5\n",
        "    grid_x = grid_loc[1]*grid_space_x+grid_space_x*0.5\n",
        "    start_loc, delta_pos = get_start_and_end(s)\n",
        "\n",
        "    loc_x = start_loc[0]\n",
        "    loc_y = start_loc[1]\n",
        "    new_x_pos = grid_x+loc_x\n",
        "    new_y_pos = grid_y+loc_y\n",
        "    result.append([new_x_pos-x_pos, new_y_pos-y_pos, 0])\n",
        "\n",
        "    result += s.tolist()\n",
        "    result[-1][2] = 1\n",
        "    x_pos = new_x_pos+delta_pos[0]\n",
        "    y_pos = new_y_pos+delta_pos[1]\n",
        "  return np.array(result)"
      ],
      "metadata": {
        "id": "GFf9fdkfVs0F"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'http://github.com/hardmaru/sketch-rnn-datasets/raw/master/aaron_sheep/'\n",
        "models_root_dir = '/tmp/sketch_rnn/models'\n",
        "model_dir = '/tmp/sketch_rnn/models/aaron_sheep/layer_norm'\n",
        "download_pretrained_models(models_root_dir=models_root_dir)"
      ],
      "metadata": {
        "id": "g1TCNZiUWJft"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_env_compatible(data_dir, model_dir):\n",
        "  \"\"\"Loads environment for inference mode, used in jupyter notebook.\"\"\"\n",
        "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
        "  # to work with depreciated tf.HParams functionality\n",
        "  model_params = sketch_rnn_model.get_default_hparams()\n",
        "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
        "    data = json.load(f)\n",
        "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
        "  for fix in fix_list:\n",
        "    data[fix] = (data[fix] == 1)\n",
        "  model_params.parse_json(json.dumps(data))\n",
        "  return load_dataset(data_dir, model_params, inference_mode=True)\n",
        "\n",
        "def load_model_compatible(model_dir):\n",
        "  \"\"\"Loads model for inference mode, used in jupyter notebook.\"\"\"\n",
        "  # modified https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/sketch_rnn_train.py\n",
        "  # to work with depreciated tf.HParams functionality\n",
        "  model_params = sketch_rnn_model.get_default_hparams()\n",
        "  with tf.gfile.Open(os.path.join(model_dir, 'model_config.json'), 'r') as f:\n",
        "    data = json.load(f)\n",
        "  fix_list = ['conditional', 'is_training', 'use_input_dropout', 'use_output_dropout', 'use_recurrent_dropout']\n",
        "  for fix in fix_list:\n",
        "    data[fix] = (data[fix] == 1)\n",
        "  model_params.parse_json(json.dumps(data))\n",
        "\n",
        "  model_params.batch_size = 1  # only sample one at a time\n",
        "  eval_model_params = sketch_rnn_model.copy_hparams(model_params)\n",
        "  eval_model_params.use_input_dropout = 0\n",
        "  eval_model_params.use_recurrent_dropout = 0\n",
        "  eval_model_params.use_output_dropout = 0\n",
        "  eval_model_params.is_training = 0\n",
        "  sample_model_params = sketch_rnn_model.copy_hparams(eval_model_params)\n",
        "  sample_model_params.max_seq_len = 1  # sample one point at a time\n",
        "  return [model_params, eval_model_params, sample_model_params]"
      ],
      "metadata": {
        "id": "v8JT3I9gWLPQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[train_set, valid_set, test_set, hps_model, eval_hps_model, sample_hps_model] = load_env_compatible(data_dir, model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "a58DiBuyWOy7",
        "outputId": "407de50e-2254-45b2-9b10-72e35e8f1f60"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d1adfb39ff73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_hps_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_hps_model\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_env_compatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-80f80cf4d671>\u001b[0m in \u001b[0;36mload_env_compatible\u001b[0;34m(data_dir, model_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msketch_rnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_hparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model_config.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mfix_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'conditional'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'use_input_dropout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'use_output_dropout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'use_recurrent_dropout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfix_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     80\u001b[0m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0;32m---> 81\u001b[0;31m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: /tmp/sketch_rnn/models/aaron_sheep/layer_norm/model_config.json; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xvV5MeT-WRXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2WWBHhA5WdIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}